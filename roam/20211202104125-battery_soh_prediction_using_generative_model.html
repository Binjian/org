<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>Battery SOH prediction using Generative Model</title>
<meta name="author" content="Binjian Xin"/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="/home/x/.emacs.d/.local/straight/build-28.2/revealjs/dist/reveal.css"/>

<link rel="stylesheet" href="/home/x/.emacs.d/.local/straight/build-28.2/revealjs/dist/theme/black.css" id="theme"/>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide">
<h1 class="title">Battery SOH prediction using Generative Model</h1><h2 class="author">Binjian Xin</h2><p class="date">Created: 2023-01-09 Mon 10:12</p>
</section>
<section id="table-of-contents-section">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#/slide-1">1. input</a>
<ul>
<li><a href="#/slide-1-1">1.1. voltage</a></li>
<li><a href="#/slide-1-2">1.2. current</a></li>
<li><a href="#/slide-1-3">1.3. &#x2026;etc</a></li>
</ul>
</li>
<li><a href="#/slide-2">2. output</a>
<ul>
<li><a href="#/slide-2-1">2.1. SOH prediction: SOC</a></li>
</ul>
</li>
<li><a href="#/slide-3">3. Use Cases:</a>
<ul>
<li><a href="#/slide-3-1">3.1. charging</a>
<ul>
<li><a href="#/slide-3-1-1">3.1.1. Fast charging</a></li>
<li><a href="#/slide-3-1-2">3.1.2. AC/DC charging</a></li>
</ul>
</li>
<li><a href="#/slide-3-2">3.2. driving</a></li>
</ul>
</li>
<li><a href="#/slide-4">4. Motivation</a>
<ul>
<li><a href="#/slide-4-1">4.1. No labels, no models</a></li>
<li><a href="#/slide-4-2">4.2. need outlier detection</a></li>
<li><a href="#/slide-4-3">4.3. unsupervised learning</a>
<ul>
<li><a href="#/slide-4-3-1">4.3.1. given a data X (one time sequence of voltage), under a specific usage (fast charging)</a></li>
<li><a href="#/slide-4-3-2">4.3.2. determine whether it&rsquo;s normal or abnormal</a></li>
<li><a href="#/slide-4-3-3">4.3.3. Most of the battery cells are OK, say 90%, to get the most of the training data (safe assumption)</a></li>
<li><a href="#/slide-4-3-4">4.3.4. check the remaining 10% to pick out the outliers</a></li>
</ul>
</li>
<li><a href="#/slide-4-4">4.4. Learn the data distribution in a high dimenional feature space X</a></li>
<li><a href="#/slide-4-5">4.5. Learn the feature unsupervised (latent variable Z)</a></li>
<li><a href="#/slide-4-6">4.6. get the latent variable Z</a></li>
<li><a href="#/slide-4-7">4.7. Conditioned on input data current value</a></li>
<li><a href="#/slide-4-8">4.8. Specification of typical use cases: fast charge, driving</a></li>
<li><a href="#/slide-4-9">4.9. Generate diverse time series under the</a></li>
</ul>
</li>
<li><a href="#/slide-5">5. Issue</a>
<ul>
<li><a href="#/slide-5-1">5.1. Limited samples for training</a>
<ul>
<li><a href="#/slide-5-1-1">5.1.1. adaptive discriminator oaugmentation</a></li>
<li><a href="#/slide-5-1-2">5.1.2. data augmentation</a></li>
</ul>
</li>
<li><a href="#/slide-5-2">5.2. discriminator overfitting early</a></li>
<li><a href="#/slide-5-3">5.3. non-convergence</a>
<ul>
<li><a href="#/slide-5-3-1">5.3.1. VAE (VQ-VAE)</a></li>
<li><a href="#/slide-5-3-2">5.3.2. DDPM</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#/slide-6">6. Retrospection</a>
<ul>
<li><a href="#/slide-6-1">6.1. TimeGAN</a>
<ul>
<li><a href="#/slide-6-1-1">6.1.1. autoencoding (embedding space, efficiency): compression, dynamics encoding (provided by embedder &amp; recovery)</a></li>
<li><a href="#/slide-6-1-2">6.1.2. apply supervised learning (objective time-frequency characteristics, fidelity) to guide adversarial learning (GAN objective): loss addition!</a></li>
<li><a href="#/slide-6-1-3">6.1.3. synchronization (of latent space for real and synthetic, e&amp;f): superviser</a></li>
<li><a href="#/slide-6-1-4">6.1.4. e, r: MLP+RNN, unidirectional (has to be causal),</a></li>
<li><a href="#/slide-6-1-5">6.1.5. g: MLP+RNN (noise: Gaussian + Wiener)</a></li>
<li><a href="#/slide-6-1-6">6.1.6. d :</a></li>
<li><a href="#/slide-6-1-7">6.1.7. not completely integral as pure VAE or GAN, bastlerei</a></li>
<li><a href="#/slide-6-1-8">6.1.8. equal weights for the additive loss of static feature and time series feature!</a></li>
<li><a href="#/slide-6-1-9">6.1.9. the claim that GAN loss alone is not sufficient is very dubious, image data has the same spatial fluctuation but is sufficient!</a></li>
<li><a href="#/slide-6-1-10">6.1.10. classification error 10~20% (~48% significantly better), prediction error MAE (normalized, 3.8&amp;~30%) events (~30%)</a></li>
</ul>
</li>
<li><a href="#/slide-6-2">6.2. no labels (expert knowledge) for supervised learning</a></li>
<li><a href="#/slide-6-3">6.3. challenge and caveats for unsuperviesd learning:</a>
<ul>
<li><a href="#/slide-6-3-1">6.3.1. relevant features to reflect intrinsic parameters of battery health</a></li>
<li><a href="#/slide-6-3-2">6.3.2. when the features are relevant, sufficient <b>finite</b> data to represent this distribution</a></li>
<li><a href="#/slide-6-3-3">6.3.3. optimal architecture for G and D (optimize weights) :</a></li>
<li><a href="#/slide-6-3-4">6.3.4. no guarantee for convergence</a></li>
<li><a href="#/slide-6-3-5">6.3.5. CGAN and feature labels?</a></li>
</ul>
</li>
<li><a href="#/slide-6-4">6.4. Future work</a>
<ul>
<li><a href="#/slide-6-4-1">6.4.1. multimodalities in TimeGAN</a></li>
<li><a href="#/slide-6-4-2">6.4.2. transformer instead of GRU</a></li>
<li><a href="#/slide-6-4-3">6.4.3. diffusion model</a></li>
<li><a href="#/slide-6-4-4">6.4.4. extreme event detection</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
</section>

<section>
<section id="slide-1">
<h2 id="1"><span class="section-number-2">1.</span> input</h2>
<div class="outline-text-2" id="text-1">
</div>
</section>
<section id="slide-1-1">
<h3 id="1-1"><span class="section-number-3">1.1.</span> voltage</h3>
</section>
<section id="slide-1-2">
<h3 id="1-2"><span class="section-number-3">1.2.</span> current</h3>
</section>
<section id="slide-1-3">
<h3 id="1-3"><span class="section-number-3">1.3.</span> &#x2026;etc</h3>
</section>
</section>
<section>
<section id="slide-2">
<h2 id="2"><span class="section-number-2">2.</span> output</h2>
<div class="outline-text-2" id="text-2">
</div>
</section>
<section id="slide-2-1">
<h3 id="2-1"><span class="section-number-3">2.1.</span> SOH prediction: SOC</h3>
</section>
</section>
<section>
<section id="slide-3">
<h2 id="3"><span class="section-number-2">3.</span> Use Cases:</h2>
<div class="outline-text-2" id="text-3">
</div>
</section>
<section id="slide-3-1">
<h3 id="3-1"><span class="section-number-3">3.1.</span> charging</h3>
<div class="outline-text-3" id="text-3-1">
</div>
</section>
<section id="slide-3-1-1">
<h4 id="3-1-1"><span class="section-number-4">3.1.1.</span> Fast charging</h4>
</section>
<section id="slide-3-1-2">
<h4 id="3-1-2"><span class="section-number-4">3.1.2.</span> AC/DC charging</h4>
</section>
<section id="slide-3-2">
<h3 id="3-2"><span class="section-number-3">3.2.</span> driving</h3>
</section>
</section>
<section>
<section id="slide-4">
<h2 id="4"><span class="section-number-2">4.</span> Motivation</h2>
<div class="outline-text-2" id="text-4">
</div>
</section>
<section id="slide-4-1">
<h3 id="4-1"><span class="section-number-3">4.1.</span> No labels, no models</h3>
</section>
<section id="slide-4-2">
<h3 id="4-2"><span class="section-number-3">4.2.</span> need outlier detection</h3>
</section>
<section id="slide-4-3">
<h3 id="4-3"><span class="section-number-3">4.3.</span> unsupervised learning</h3>
<div class="outline-text-3" id="text-4-3">
</div>
</section>
<section id="slide-4-3-1">
<h4 id="4-3-1"><span class="section-number-4">4.3.1.</span> given a data X (one time sequence of voltage), under a specific usage (fast charging)</h4>
</section>
<section id="slide-4-3-2">
<h4 id="4-3-2"><span class="section-number-4">4.3.2.</span> determine whether it&rsquo;s normal or abnormal</h4>
</section>
<section id="slide-4-3-3">
<h4 id="4-3-3"><span class="section-number-4">4.3.3.</span> Most of the battery cells are OK, say 90%, to get the most of the training data (safe assumption)</h4>
</section>
<section id="slide-4-3-4">
<h4 id="4-3-4"><span class="section-number-4">4.3.4.</span> check the remaining 10% to pick out the outliers</h4>
</section>
<section id="slide-4-4">
<h3 id="4-4"><span class="section-number-3">4.4.</span> Learn the data distribution in a high dimenional feature space X</h3>
</section>
<section id="slide-4-5">
<h3 id="4-5"><span class="section-number-3">4.5.</span> Learn the feature unsupervised (latent variable Z)</h3>
</section>
<section id="slide-4-6">
<h3 id="4-6"><span class="section-number-3">4.6.</span> get the latent variable Z</h3>
</section>
<section id="slide-4-7">
<h3 id="4-7"><span class="section-number-3">4.7.</span> Conditioned on input data current value</h3>
</section>
<section id="slide-4-8">
<h3 id="4-8"><span class="section-number-3">4.8.</span> Specification of typical use cases: fast charge, driving</h3>
</section>
<section id="slide-4-9">
<h3 id="4-9"><span class="section-number-3">4.9.</span> Generate diverse time series under the</h3>
</section>
</section>
<section>
<section id="slide-5">
<h2 id="5"><span class="section-number-2">5.</span> Issue</h2>
<div class="outline-text-2" id="text-5">
</div>
</section>
<section id="slide-5-1">
<h3 id="5-1"><span class="section-number-3">5.1.</span> Limited samples for training</h3>
<div class="outline-text-3" id="text-5-1">
</div>
</section>
<section id="slide-5-1-1">
<h4 id="5-1-1"><span class="section-number-4">5.1.1.</span> adaptive discriminator oaugmentation</h4>
</section>
<section id="slide-5-1-2">
<h4 id="5-1-2"><span class="section-number-4">5.1.2.</span> data augmentation</h4>
</section>
<section id="slide-5-2">
<h3 id="5-2"><span class="section-number-3">5.2.</span> discriminator overfitting early</h3>
</section>
<section id="slide-5-3">
<h3 id="5-3"><span class="section-number-3">5.3.</span> non-convergence</h3>
<div class="outline-text-3" id="text-5-3">
</div>
</section>
<section id="slide-5-3-1">
<h4 id="5-3-1"><span class="section-number-4">5.3.1.</span> VAE (VQ-VAE)</h4>
</section>
<section id="slide-5-3-2">
<h4 id="5-3-2"><span class="section-number-4">5.3.2.</span> DDPM</h4>
</section>
</section>
<section>
<section id="slide-6">
<h2 id="6"><span class="section-number-2">6.</span> Retrospection</h2>
<div class="outline-text-2" id="text-6">
</div>
</section>
<section id="slide-6-1">
<h3 id="6-1"><span class="section-number-3">6.1.</span> TimeGAN</h3>
<div class="outline-text-3" id="text-6-1">
</div>
</section>
<section id="slide-6-1-1">
<h4 id="6-1-1"><span class="section-number-4">6.1.1.</span> autoencoding (embedding space, efficiency): compression, dynamics encoding (provided by embedder &amp; recovery)</h4>
</section>
<section id="slide-6-1-2">
<h4 id="6-1-2"><span class="section-number-4">6.1.2.</span> apply supervised learning (objective time-frequency characteristics, fidelity) to guide adversarial learning (GAN objective): loss addition!</h4>
</section>
<section id="slide-6-1-3">
<h4 id="6-1-3"><span class="section-number-4">6.1.3.</span> synchronization (of latent space for real and synthetic, e&amp;f): superviser</h4>
<div class="outline-text-4" id="text-6-1-3">
</div>
<ol class="org-ol">
<li><a id="6-1-3-1"></a>let generator learn the dynamics of the actual data distribution in latent space<br /></li>
</ol>
</section>
<section id="slide-6-1-4">
<h4 id="6-1-4"><span class="section-number-4">6.1.4.</span> e, r: MLP+RNN, unidirectional (has to be causal),</h4>
<div class="outline-text-4" id="text-6-1-4">
</div>
<ol class="org-ol">
<li><a id="6-1-4-1"></a>deterministic Encoder-Decoder， add probabilistic spin!<br /></li>
<li><a id="6-1-4-2"></a>r might not be necessary!<br /></li>
</ol>
</section>
<section id="slide-6-1-5">
<h4 id="6-1-5"><span class="section-number-4">6.1.5.</span> g: MLP+RNN (noise: Gaussian + Wiener)</h4>
<div class="outline-text-4" id="text-6-1-5">
</div>
<ol class="org-ol">
<li><a id="6-1-5-1"></a>\(\mathcal{Z}_{\mathcal{S}}\) and \(\mathcal{Z}_t\) is the real latent of the latent, not the same space as \(\mathcal{S}\) and \(\mathcal{X}_t\)<br /></li>
</ol>
</section>
<section id="slide-6-1-6">
<h4 id="6-1-6"><span class="section-number-4">6.1.6.</span> d :</h4>
<div class="outline-text-4" id="text-6-1-6">
</div>
<ol class="org-ol">
<li><a id="6-1-6-1"></a>bidirectional(?): as discriminator doesn&rsquo;t have to be causal, retrospective, add capacity) RNN + MLP,<br /></li>
<li><a id="6-1-6-2"></a>\(\tilde{y}_{\mathcal{S}}\) (boolean for static features), \(\tilde{y}_{1:T}\) a boolean on every timestamp (necessary?): true/false has dynamics, timing capacity, then summarization<br /></li>
</ol>
</section>
<section id="slide-6-1-7">
<h4 id="6-1-7"><span class="section-number-4">6.1.7.</span> not completely integral as pure VAE or GAN, bastlerei</h4>
</section>
<section id="slide-6-1-8">
<h4 id="6-1-8"><span class="section-number-4">6.1.8.</span> equal weights for the additive loss of static feature and time series feature!</h4>
</section>
<section id="slide-6-1-9">
<h4 id="6-1-9"><span class="section-number-4">6.1.9.</span> the claim that GAN loss alone is not sufficient is very dubious, image data has the same spatial fluctuation but is sufficient!</h4>
</section>
<section id="slide-6-1-10">
<h4 id="6-1-10"><span class="section-number-4">6.1.10.</span> classification error 10~20% (~48% significantly better), prediction error MAE (normalized, 3.8&amp;~30%) events (~30%)</h4>
</section>
<section id="slide-6-2">
<h3 id="6-2"><span class="section-number-3">6.2.</span> no labels (expert knowledge) for supervised learning</h3>
</section>
<section id="slide-6-3">
<h3 id="6-3"><span class="section-number-3">6.3.</span> challenge and caveats for unsuperviesd learning:</h3>
<div class="outline-text-3" id="text-6-3">
</div>
</section>
<section id="slide-6-3-1">
<h4 id="6-3-1"><span class="section-number-4">6.3.1.</span> relevant features to reflect intrinsic parameters of battery health</h4>
<div class="outline-text-4" id="text-6-3-1">
</div>
<ol class="org-ol">
<li><a id="6-3-1-1"></a>the distribution of battery health state depending on those parameters<br /></li>
</ol>
</section>
<section id="slide-6-3-2">
<h4 id="6-3-2"><span class="section-number-4">6.3.2.</span> when the features are relevant, sufficient <b>finite</b> data to represent this distribution</h4>
<div class="outline-text-4" id="text-6-3-2">
</div>
<ol class="org-ol">
<li><a id="6-3-2-1"></a>Example: Gaussian/uniform; GT distribution is the unknown (nonlinear, multimodal, non-stationary) natural density of data: distribution \(p_{\xi}\) &#x2013;&gt; Neural Network v\(p_{\theta}\)<br />
<ol class="org-ol">
<li><a id="6-3-2-1-1"></a>NN very versatile: \(p_{\theta}\) can approxmate any distribution!<br /></li>
<li><a id="6-3-2-1-2"></a>prior \(p(z)\) has an impact on the final sample and capability of the whole network: \(p(z) \odot p_{\theta}(x)\)<br /></li>
<li><a id="6-3-2-1-3"></a>if enough expert knowledge is available tell us it&rsquo;s normal distribution, just 2 parameters to estimate, still a lot of samples for bootstrapping/bagging, sample mean / sample variance, need confidence level, statistical trial for inspection.<br /></li>
</ol>
</li>
<li><a id="6-3-2-2"></a>scenario data (time sequences of specific scenes)<br /></li>
<li><a id="6-3-2-3"></a>given the current compute resources: the way to go is to reduce the data amount requirement by defining relevant features and relevant scenarios<br /></li>
</ol>
</section>
<section id="slide-6-3-3">
<h4 id="6-3-3"><span class="section-number-4">6.3.3.</span> optimal architecture for G and D (optimize weights) :</h4>
<div class="outline-text-4" id="text-6-3-3">
</div>
<ol class="org-ol">
<li><a id="6-3-3-1"></a>multidimensional continuous function enough? More expertise to make this happen!<br />
<ol class="org-ol">
<li><a id="6-3-3-1-1"></a>transformer for sequential modeling<br /></li>
<li><a id="6-3-3-1-2"></a>make prior learnable<br /></li>
</ol>
</li>
<li><a id="6-3-3-2"></a>optimal hyperparameters?<br /></li>
</ol>
</section>
<section id="slide-6-3-4">
<h4 id="6-3-4"><span class="section-number-4">6.3.4.</span> no guarantee for convergence</h4>
</section>
<section id="slide-6-3-5">
<h4 id="6-3-5"><span class="section-number-4">6.3.5.</span> CGAN and feature labels?</h4>
</section>
<section id="slide-6-4">
<h3 id="6-4"><span class="section-number-3">6.4.</span> Future work</h3>
<div class="outline-text-3" id="text-6-4">
</div>
</section>
<section id="slide-6-4-1">
<h4 id="6-4-1"><span class="section-number-4">6.4.1.</span> multimodalities in TimeGAN</h4>
<div class="outline-text-4" id="text-6-4-1">
</div>
<ol class="org-ol">
<li><a id="6-4-1-1"></a>Gaussian mixture model in latent space<br /></li>
</ol>
</section>
<section id="slide-6-4-2">
<h4 id="6-4-2"><span class="section-number-4">6.4.2.</span> transformer instead of GRU</h4>
</section>
<section id="slide-6-4-3">
<h4 id="6-4-3"><span class="section-number-4">6.4.3.</span> diffusion model</h4>
</section>
<section id="slide-6-4-4">
<h4 id="6-4-4"><span class="section-number-4">6.4.4.</span> extreme event detection</h4>
</section>
</section>
</div>
</div>
<script src="/home/x/.emacs.d/.local/straight/build-28.2/revealjs/dist/reveal.js"></script>
<script src="/home/x/.emacs.d/.local/straight/build-28.2/revealjs/plugin/markdown/markdown.js"></script>
<script src="/home/x/.emacs.d/.local/straight/build-28.2/revealjs/plugin/notes/notes.js"></script>
<script src="/home/x/.emacs.d/.local/straight/build-28.2/revealjs/plugin/search/search.js"></script>
<script src="/home/x/.emacs.d/.local/straight/build-28.2/revealjs/plugin/zoom/zoom.js"></script>
<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

controls: true,
progress: true,
history: false,
center: true,
slideNumber: 'c',
rollingLinks: false,
keyboard: true,
mouseWheel: false,
fragmentInURL: false,
hashOneBasedIndex: false,
pdfSeparateFragments: true,
overview: true,

transition: 'convex',
transitionSpeed: 'default',

// Plugins with reveal.js 4.x
plugins: [ RevealMarkdown, RevealNotes, RevealSearch, RevealZoom ],

// Optional libraries used to extend reveal.js
dependencies: [
]

});
</script>
</body>
</html>
