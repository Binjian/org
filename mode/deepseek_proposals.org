#+title: DeepSeek调研报告及应用展望
#+AUTHOR: 忻斌健
#+CREATOR: 忻斌健
#+DATE:<2025-01-02 周四>
#+STARTUP: latexpreview
#+LATEX_COMPILER: xelatex
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [a4paper, 11pt]
#+LATEX_HEADER: \usepackage{svg}
#+LATEX_HEADER: \usepackage{tikz}
#+LATEX_HEADER: \usetikzlibrary{positioning,shapes.symbols, calc}
# #+LATEX_HEADER: \usepackage{tikzmark}
#+LANGUAGE: zh-CN
#+OPTIONS: tex:t
#+OPTIONS: ^:{}
#+bind: org-export-publishing-directory "./exports"
#+DOWNLOAD_IMAGE_DIR:  '~/.org.d/mode/img'
#+OPTIONS: reveal_center:t reveal_progress:t reveal_history:t reveal_control:t
#+OPTIONS: reveal_mathjax:t reveal_rolling_links:t reveal_keyboard:t reveal_overview:t num:nil
#+REVEAL_MATHJAX_URL: https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-svg-full.js
#+OPTIONS: reveal_width:1280 reveal_height:800
#+OPTIONS: toc:1
#+REVEAL_INIT_OPTIONS: transition: 'cube'
#+REVEAL_MARGIN: 0.005
#+REVEAL_MIN_SCALE: 0.01
#+REVEAL_MAX_SCALE: 2.5
#+REVEAL_THEME: sky
#+REVEAL_HLEVEL: 1
#+REVEAL_EXTRA_CSS: ./templates/drl101.css
#+REVEAL_PLUGINS: (highlight notes)
#+REVEAL_TITLE_SLIDE: ./templates/title_deepseek_proposals.html
#+REVEAL_TITLE_SLIDE_BACKGROUND: ./img/deepseek/ds_logo.png
#+REVEAL_TITLE_SLIDE_BACKGROUND_SIZE: 1600px
#+REVEAL_TITLE_SLIDE_BACKGROUND_OPACITY: 0.5
#+HTML_HEAD_EXTRA: <style> .figure p {text-align: center;}</style>
#+HTML_HEAD_EXTRA: <style>*{font-family: "LXGW WenKai Mono" !important}</style>
#+MACRO: color @@html:<font color="$1">$2</font>@@

* 背景
** 深度学习与神经网络
#+ATTR_REVEAL: :frag (appear)
- 基于机器学习
- 神经网络
  - 可从数据中学习，可以碎片化学习
  - 学习能力强
  - 学习容量大
- 强化学习：
  - 数据饥渴
  - 可以从复杂系统的碎片化经验中学习
** 苦涩的教训(Rich Sutton)
#+begin_quote
大部分人工智能和强化学习领域的进步来源于利用大量计算资源和通用学习算法，而不是依赖领域专家手工设计的特定知识。
#+end_quote
#+ATTR_REVEAL: :frag (appear)
- 学习算法的优势(规模化能力)
  #+ATTR_REVEAL: :frag (appear)
  - 专门设计的系统不利于规模化部署
  - 长期来看依赖计算和数据得来的策略更加稳健和高效
  - 通用算法能随着算力增加而不断提升表现
- 自动发现的重要性
  #+ATTR_REVEAL: :frag (appear)
  - 让系统通过数据和计算自动发现问题的最佳解
  - 非在细节上进行过多手工调优
  - 数据驱动,解除模型学习的限制
   #+begin_notes
   - 规模化能力、
     - 短期内利用人工经验可能有帮助，
     - 专家系统：需要工程团队维护规则算法，随着系统复杂度增加（必然性）不可维护
     - 比人类预先嵌入的智慧更为持久且具适应性
   - 自动发现有利于工程化
     - 将精力放在利用大规模计算和数据上
     - 推动了深度学习及强化学习等领域的革命性进步
   - 数据驱动：高质量数据非常重要
   #+end_notes
** 深度神经网络的发展历史

#+NAME: dl_history
#+ATTR_HTML: :alt  :title  :width 800px  :align center
#+attr_org: :width 400px
[[./img/deepseek/dl_histroy.png]]
# #+begin_src mermaid :file ./img/deepseek/dl_histroy.png
# block-beta
#     columns 4
#     id1(("AlexNet<br/>2014")) id2(("ResNets<br/>2015")) id3(("Transformer<br/>2017")) id4(("GPT,BERT<br/>2018"))
#     id8(("GPT4<br/>2023")) id7(("ChatGPT<br/>Chinchilla<br/>2022")) id6(("GPT3<br/>2020")) id5(("GPT2<br/>2019"))
#     id9(("Llama2<br/>2023")) id10(("o1<br/>2024")) id11(("r1<br/>2024")) id12(("s1<br/>o3 mini<br/>2024"))
#     id1-->id2
#     id2-->id3
#     id3-->id4
#     id4-->id5
#     id5-->id6
#     id6-->id7
#     id7-->id8
#     id8-->id9
#     id9-->id10
#     id10-->id11
#     id11-->id12
#
#
#     classDef fill fill:#696
#     class id11 fill
# #+end_src

** $\mathcal{R}1$ 的认知模型
#+ATTR_HTML: :alt  :title 技术进步 :width 600px  :align center
#+attr_org: :width 300px :align left
[[./img/deepseek/autoregressive.png]]

#+ATTR_REVEAL: :frag (appear)
- 所有大语言模型是自回归模型
- 标记(token)
- 回答是通过随机抽样得到
- 低概率,高精度

#+begin_notes
- 采样和统计模型
- 提问是条件，回答是条件概率
- 温度参数: 可以调节随机性
- fp32 单精度浮点数精度：可以表示的最小标称正数 $1.18\times 10^{-38}$
- fp16： $5.96\times 10^{-8}$
- fp8 1.4.3: 0.0156
#+end_notes

** 幻觉
#+REVEAL_HTML: <div class="gridded_frame_with_columns">
     #+REVEAL_HTML: <div class="one_of_2_columns">
        #+ATTR_HTML: :alt  :title  :width 400pix  :align center
        #+attr_org: :width 400px :align left
        [[./img/deepseek/hallucination.jpg]]
     #+REVEAL_HTML: </div>
     #+REVEAL_HTML: <div class="one_of_2_columns">
        #+ATTR_REVEAL: :frag (appear)
        - 大语言模型是自回归模型采样
        - 优化使用需要训练模型
          - 应用域数据收集整理
          - 模型微调/强化学习训练
     #+REVEAL_HTML: </div>

* 模型的演变
#+ATTR_REVEAL: :frag (appear)
- 开源最前沿模型(V0)
  - 网络基本架构
    - _LLaMA_ (变形金刚模型)+ _RMSNorm+SwiGLU_, _GQA_, _RoPE_
  - 训练
    - _SFT,DPO,Flash Attention_,bf16+fp32, _vLLM_,BBPE, _MTP_,ZeRO
- 提取高质量数据集(V0~$\mathcal{R}1$)
  - 高质量数据集(2T), DeepSeekMath,CoT,代码
- *增量式创新* (V1~$\mathcal{R}1_{0}$)
  - 细颗粒力度混合专家架构 (*DeepseekMoE*): 2+64/4+128/1+256
  - 多头隐注意力 (*MLA*)
  - *数据路由均衡* (端到端训练)
- 训练方法上的创新($\mathcal{R}1$)
  - *纯强化学习训练*: *GRPO*

#+begin_notes
- 历史
  - LLM->MoE->V2->V3->Math->Zero->$\mathcal{R}1$
  - 2024.01~2025.01
  - _GPT4时代还没有_
  - Mixtral 0/8 ➡GPT4➡DeepSeekMoE➡V3
  - 训练方法上的创新
    - 冷启动数据训练
    - 分阶段训练
    - 微调训练与后训练，附加强化学习训练
    - 蒸馏:基于QWen2.5/Llama3 (优于纯RL)，
#+end_notes

** $\mathcal{R}1$($\mathcal{R}1_0$)模型架构
#+REVEAL_HTML: <div class="gridded_frame_with_columns">
     #+REVEAL_HTML: <div class="one_of_2_columns">
        #+ATTR_HTML: :alt  :title  :width 600pix  :align center
        #+attr_org: :width 600px :align left
        #+CAPTION: $\mathcal{R}1_0$ 网络模型
        #+NAME: model
        [[./img/deepseek/deepseek_v3.png]]
     #+REVEAL_HTML: </div>
     #+REVEAL_HTML: <div class="one_of_2_columns">
        #+ATTR_HTML: :alt  :title tree :width 600pix  :align center
        #+attr_org: :width 600px :align left
        #+CAPTION: 强化学习训练引发推理能力提升
        #+NAME: RL elicits reasoning!
        [[./img/deepseek/reasoning_increase.png]]
     #+REVEAL_HTML: </div>
#+REVEAL_HTML: </div>
** $\mathcal{R}1$ 训练流水
#+ATTR_HTML: :alt  :title tree :width 1000pix  :align center
#+attr_org: :width 800px :align left
#+NAME: position
[[./img/deepseek/the-real-deepseek-r1-schematic-v0.gif]]

** 主要特点
#+ATTR_REVEAL: :frag (appear)
- 开源大模型(权重开放，方法开放，非常宽松的MIT许可)
  - 容易复制，已经被多次复现(Open$\mathcal{R}1$)改进(S1)
  - 非视觉多模态模型→ DreamCraft3D, Janus Pro (79.2%@MMBench, 0.8@t2i)
- 较强的推理能力
  - 来自强化学习训练和推理数据训练样本
  - 大模型的推理能力可蒸馏到小模型
- 高效(较低成本)
  - 架构：训练和推理稀疏化(MoE) + 内嵌瓶颈层(MLA) + (MTP）
  - 硬件驱动: 匹配通信约束跨节点数据流,低精度浮点数计算

#+begin_notes
  - 国内其他大模型公司:科大讯飞，腾讯云，百度，阿里千问,华为盘古：模型和应用？
  - 24年底，六小龙大模型公司的减法： 商汤日日新,零一万物,百川,智谱GLM,月之暗面Kimi,MiniMax海螺AI？
  - Demis Hassabis: 过度炒作，没有科学上的进步，已知技术，基于谷歌，Meta和开源的成果）
#+end_notes
* 启示
#+ATTR_REVEAL: :frag (appear)
- 开发模式
  - 采用通用基础大模型
  - SoTA+递增式改进+实验验证
- 提高模型性能的方法
  - 模型和驱动架构
  - 高质量数据集
  - 推理能力可以蒸馏到较小模型
- 幻方量化:量化基金以AI为核心的量化基金

** 幻方量化(High-Flyer)发展
#+ATTR_REVEAL: :frag (appear)
- 2020 2亿人民币超算一代
  - 参照美国“文艺复兴科技”
- 2021 10亿人民币超算二代(10000 A100)
  - 旗下100支基金产品亏损超10%
  - 总体回报率20%~50%
- 2022 建议客户回撤资金
- 2023 4月成立Deepseek,专注通用人工智能研究
- 2024 1月DeepSeekLLM,DeepSeekMoE开源
- 2024 2月国家打击量化基金扰乱股市
  - 业绩落后综合指数4%
- 2024 10月因轧空关闭中性基金产品
- 2025 1月Deepseek $\mathcal{R}1$ 开源

* 大模型应用
#+ATTR_REVEAL: :frag (appear)
- 汽车行业端到端大模型
  - 车机应用:LLM,对话，感知
  - 感知大模型:车道,行人,障碍物识别
  - 车辆控制(VLA,生成式模型):世界大模型
- 机器人行业
  - 规模化控制模型(VLA,生成式扩散模型,块变形金刚模型)
  - 机械臂操作:模仿学习
  - 双足/四足机器人行走控制:强化学习

** 大模型的应用模式
#+ATTR_HTML: :alt  :title  :width 800pix  :align center
#+attr_org: :width 600px :align left
#+NAME: model deployment
[[./img/deepseek/llm_mentalmodel.jpg]]

#+ATTR_REVEAL: :frag (appear)
- 人机接口(HMI,前端)
- 大语言模型($\mathcal{R}1$,后端)
- 应用域数据源(问题适配,中台)

#+BEGIN_NOTES
https://medium.com/towards-data-science/building-ai-products-with-a-holistic-mental-model-33f8729e3ad9
#+END_NOTES

** $\mathcal{R}1$ 推理模型和制造与工业自动化:
#+begin_quote
添加图像编解码网络
#+end_quote
#+ATTR_REVEAL: :frag (appear)
- 工业自动化
  - 可用于自动化装配线:可以帮助机器人准确地执行装配任务
  - 质量检测:减少错误和不合格品
- 质量控制
  - 通过视觉系实时检测产品缺陷
  - 建立故障模型预测
  - 预测性维护(匹配时间序列数据)
- 移动机器人
  - 复杂任务调度
  - 路径规划
** 数据处理
#+ATTR_REVEAL: :frag (appear)
- OA助手
  - 办公文本生成
  - 表格数据分析和报告生成
- 编程助手
  - 专用领域编程模型
  - 架构辅助设计
  - 文档和测试自动化
** 机器人
#+begin_quote
结合$\mathcal{R}1$ 微调开源VLA基础模型
#+end_quote
#+ATTR_REVEAL: :frag (appear)
- X1
  - 敏捷步态控制
  - 复杂机械臂操作
- 焊接机器人
  - 复杂路径规划与控制
  - 零示教自适应多任务控制
- 移动机器人规划
  - 路径规划
** 开发工作
#+ATTR_REVEAL: :frag (appear)
- 服务部署
  - 企业内网后端服务
  - 前端界面开发和集成
- 提示工程
  - 系统化整理提示模板
  - 监控，维护和更新
  - 使用培训
*** 不同应用域的适配开发模式
#+ATTR_REVEAL: :frag (appear)
- 数据
  - 收集，清洗，
  - 数据集维护和更新
- 模型微调
  - 应用域滚动训练
  - 超参调试
  - 架构调整
  - 训练调度测试
*** 计算资源
#+ATTR_REVEAL: :frag (appear)
- 行为克隆训练
  - Diffusion Policy (TRI)
    - 单场景:50~100演示,12小时
      - ~3随机种子x50
      - 网络尺寸
    - 决策网训练(CNN/VIiT)
      - 8*A100/H100
      - 3.34百万次仿真/每个操作任务
      - 权重数据：650MB~4GB/每个操作任务
    - 任务微调
    - 泛化到多场景，互联网级别视频（GPT）
- 训练
  - 预训练
    - 比较，评估不同架构，超参，策略
  - 强化学习训练
  - 微调监督训练
- 推理
- 仿真：英伟达IsaacSim配置建议
  - 8*A100@80GB,H800/H100/B100
  - 8*A6000@48GB
  - 8*4090
*** [[https://towardsai.net/p/artificial-intelligence/guide-to-hardware-requirements-for-training-and-fine-tuning-large-language-models][训练基础大模型的资源]]
- 70亿参数模型预训练
  - 4*4090(24GB)/A100(40GB) ~ 4*A100(80GB)
  - 1万亿字符训练集，一个月@4*A100(40GB),11万元~22万元
  - 数据集：1~5万亿
  - 权重数据：500GB
  - 微调: 1*A6000(24~48GB)/4090(24GB)~2*4090
- 700亿参数模型预训练
  - 16*A100(40GB)~32A100(40GB)
  - 10万亿字符训练集，一个月@32*A100(40GB),360万元~720万元
  - 数据集：10~20万亿
  - 权重数据：2TB
  - 微调: 8*A100(40~80GB)/H100(80GB)/4090(24GB)
*** 机器人项目(机器学习)
- [[https://agile.human2humanoid.com/][ASAP]]
- [[https://easypapersniper.github.io/projects/robotMover/robotMover.html][RobotMover]]
- [[https://dex-vla.github.io/][DexVLA]]
- [[https://dextrah-rgb.github.io/][DextrAH-RGB]]
- [[https://sam2act.github.io/][SAM2ACT]]
- 训练：编码器，策略，
