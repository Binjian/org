:PROPERTIES:
:ID:       f949414e-7ddf-4d0f-b2b0-d27c2644a498
:END:
#+title: veos-paper draft
[[id:228e200d-6679-453b-af68-788ed82029d6][veos]]
* motivation
alex irpan paper post why reinforcement leanring does not work yet in the real world
scaling up model, is not the case
1. Simulation atari
2. Carla
3. server cluster VAC
4. Bonsai

make some progress, any progress in the application;


learning based.

driving decision with short horizon has an impact on the overall energy consumption

no realtime requirement, based on the scenario, minutes would be sufficient. actuallly the luxuray of seconds updating the nearby rows of torque table.

Contextual Information like NLU different scenario, any action is like tokens. --> Sequential decision by transformer/RNN

extract driving mode from large data in a online-learning mode.


* sota

* method

** model
*** vehicle dynamic system modeling
**** general model
*** reinforcement learning model
**** action model: torque model, translational mixed gaussian model, with speed translation invariance
equation
**** observation model: state,
equation
**** **reward model**
no artificial reward points but true reward, the energy consumuption
**** driver model
driving style

** time sequence is important for exact reward
** data pool with dask and mongodb for easy sampling, storing, indexing, data interface with DataFrame with every timestamps
** system
*** signal interface
*** signal flow diagram
* experiment results discussion
** ddpg
short period of attention window
** driving style hinted at a common reward of human drive and agent

** rdpg
long episode truncated BPTT long period of attention window
episode management, training selection,

RLHF? easy way with empirical distribution no sequential model, first ignore the time sequence, just to look at the difference.
** driving style
** multimodal
** transfer

* future worok
*** add sequence model for driving style identification e2e way.
*** utilizing offline data CGL
*** improve learning efficiency by
*** federated learning for meta learning,evolving

* broader impact
NAS,
