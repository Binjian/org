#+title: DeepSeek概要
#+AUTHOR: 忻斌健
#+CREATOR: 忻斌健
#+DATE:<2025-01-02 周四>
#+STARTUP: latexpreview
#+LATEX_COMPILER: xelatex
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [a4paper, 11pt]
#+LATEX_HEADER: \usepackage{svg}
#+LATEX_HEADER: \usepackage{tikz}
#+LATEX_HEADER: \usetikzlibrary{positioning,shapes.symbols, calc}
#+LATEX_HEADER: \usepackage{tikzmark}
#+LANGUAGE: zh-CN
#+OPTIONS: tex:t
#+OPTIONS: ^:{}
#+bind: org-export-publishing-directory "./exports"
#+DOWNLOAD_IMAGE_DIR:  '~/.org.d/mode/img'
#+OPTIONS: reveal_center:t reveal_progress:t reveal_history:t reveal_control:t
#+OPTIONS: reveal_mathjax:t reveal_rolling_links:t reveal_keyboard:t reveal_overview:t num:nil
#+OPTIONS: reveal_width:1280 reveal_height:800
#+OPTIONS: toc:1
#+REVEAL_INIT_OPTIONS: transition: 'cube'
#+REVEAL_MARGIN: 0.005
#+REVEAL_MIN_SCALE: 0.01
#+REVEAL_MAX_SCALE: 2.5
#+REVEAL_THEME: sky
#+REVEAL_HLEVEL: 1
#+REVEAL_EXTRA_CSS: ./templates/drl101.css
#+REVEAL_PLUGINS: (highlight notes)
#+REVEAL_TITLE_SLIDE: ./templates/title_deepseek_report.html
#+REVEAL_TITLE_SLIDE_BACKGROUND: ./img/deepseek/ds_logo.png
#+REVEAL_TITLE_SLIDE_BACKGROUND_SIZE: 1600px
#+REVEAL_TITLE_SLIDE_BACKGROUND_OPACITY: 0.5
#+HTML_HEAD_EXTRA: <style> .figure p {text-align: center;}</style>
#+HTML_HEAD_EXTRA: <style>*{font-family: "LXGW WenKai Mono" !important}</style>
#+MACRO: color @@html:<font color="$1">$2</font>@@

* 背景
** 深度学习与神经网络
#+ATTR_REVEAL: :frag (appear)
- 基于机器学习
- 神经网络
  - 可从数据中学习，可以碎片化学习
  - 学习能力强
  - 学习容量大
- 强化学习：
  - 数据饥渴
  - 可以从复杂系统的碎片化经验中学习
** 苦涩的教训(Rich Sutton)
#+begin_quote
大部分人工智能和强化学习领域的进步来源于利用大量计算资源和通用学习算法，而不是依赖领域专家手工设计的特定知识。
#+end_quote
#+ATTR_REVEAL: :frag (appear)
- 学习算法的优势(扩展律)
  #+ATTR_REVEAL: :frag (appear)
  - 专门设计的系统往往在缩放上受限
  - 通用算法能随着算力增加而不断提升表现
- 自动发现的重要性
  #+ATTR_REVEAL: :frag (appear)
  - 让系统通过数据和计算自动发现问题的最佳解
  - 比人类预先嵌入的智慧更为持久且具适应性
  - 高质量数据非常重要

   #+begin_notes
   - 对比专家系统：需要工程团队维护规则算法，随着系统复杂度增加（必然性）不可维护
   #+end_notes
** 设计的权衡
#+ATTR_REVEAL: :frag (appear)
- 已经影响了很多现代AI系统的发展
  #+ATTR_REVEAL: :frag (appear)
  - 推动了深度学习及强化学习等领域的革命性进步
- 短期内利用人工经验可能有帮助，
  #+ATTR_REVEAL: :frag (appear)
  - 长期来看依赖计算和数据得来的策略更加稳健和高效
  - 有利于工程化
- 鼓励采用更简单、通用的算法架构
  #+ATTR_REVEAL: :frag (appear)
  - 非在细节上进行过多手工调优。
  + 将精力放在利用大规模计算和数据上
* Deepseek模型开发的历史
** V0~V1
#+ATTR_REVEAL: :frag (appear)
- V0 (DeepSeek LLM, Chat, 2024.01,SoTA基准模型)
  - 高质量数据集(2T,去重,过滤,重排),编码(BBPE),
  - 训练(*SFT,DPO,Flash Attention*, bf16+fp32, *vLLM*, *RoPE*, ZeRO) → *GPT4时代还没有*
  - 网络架构基本 *LLaMA* + *RMSNorm* + *SwiGLU*, *GQA* (非MHA/R1 *MLA*)
  - 扩展律
- V1 (_DeepSeekMoE_,2024.01, Mixtral➡GPT4➡DeepSeekMoE)
  - 专家混合架构(MoE): 2+64/4+128 (Mixtral 0/8)/每层
  - 数据路由均衡(端到端训练): 专家网络层级，设备层级
  - 扩展律
** V2~V3
#+ATTR_REVEAL: :frag (appear)
- V2
  - _多头隐注意力(MLA Multihead Latent Attention)_ : _KV cache_,主动编码瓶颈
  - _解耦RoPE_ (Decoupled RoPE)：适配MLA的RoPE
  - 完善改进数据路由均衡：增加主动设备数瓶颈,增加 _通信目标损失函数_ ,动态数据丢弃
- V3
  - MoE:(1/256)/每层
  - 数据路由均衡: _无均衡损失负载均衡_ (MoE近似分偏置参数法) + _补充序列辅助损失_
  - 多令牌预测(*MTP*)
** DeepseekMath~R1 Zero
#+ATTR_REVEAL: :frag (appear)
- DeepseekMath
  - 高质量数据集: 从开源数据集提炼高质量训练数据(DeepSeekMath)，CoT数据，代码数据(+)，arxiv论文(-)
  - _GRPO_
- R1 Zero
  - _纯强化学习训练_
  - _奖励函数仍是通过规则得到_ （精确度+格式), 非神经网络模型
  - _长链路思考_ (CoT数据和强化学习训练的自然结果)
  - 失败的尝试：过程奖励模型，蒙特卡洛搜索
** R1
#+ATTR_REVEAL: :frag (appear)
- 冷启动数据训练
- 分阶段训练
- 微调训练与后训练，附加强化学习训练
- 蒸馏:基于QWen2.5/Llama3 (优于纯RL)，
* 主要特点
#+ATTR_REVEAL: :frag (appear)
- 开源大模型(权重开放，方法开放，非常宽松的MIT许可)
  - 已经被多次复现
- 较强的推理能力
  - 来自数学知识和代码训练样本
* 启示
#+ATTR_REVEAL: :frag (appear)
- 简单架构
  - 通用人工智能
  - SoTA+递增式改进+实验验证
- 提高学习的效率,重点在数据收集和模型适配训练
  - 数据
  - 架构（MLA，编码容量瓶颈)
  - 通信（适配大数据动态）
- 推理能力可以蒸馏到较小模型（大模型的推理能力是关键）
* 应用
#+ATTR_REVEAL: :frag (appear)
- 制造与工业自动化: R1 模型可用于 自动化装配线 和 质量检测。
  - 精准装配：R1 可以帮助机器人准确地执行装配任务，减少错误和不合格品。
  - 质量控制：通过视觉系统和传感器数据，R1 能够实时检测产品缺陷，确保生产质量。
- 数据处理
  - OA助手
  - 编程
- 机器人
  - X1
  - 焊接机器人
  - 移动规划
