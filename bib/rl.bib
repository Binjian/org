@Online{chi23:_diffus_polic,
  author          = {Cheng Chi AND Zhenjia Xu AND Siyuan Feng AND Eric Cousineau
                  AND Yilun Du AND Benjamin Burchfiel AND Russ Tedrake AND
                  Shuran Song},
  title           = {{Diffusion Policy: Visuomotor Policy Learning via Action
                  Diffusion}},
  year            = 2023,
  eprint          = {2303.04137v5},
  primaryclass    = {cs.RO},
  archiveprefix   = {arXiv}
}

@Online{hansen-estruch23:_idql,
  author          = {Philippe Hansen-Estruch AND Ilya Kostrikov AND Michael
                  Janner AND Jakub Grudzien Kuba AND Sergey Levine},
  title           = {{IDQL: Implicit Q-Learning as an Actor-Critic Method with
                  Diffusion Policies}},
  year            = 2023,
  eprint          = {2304.10573v2},
  primaryclass    = {cs.LG},
  archiveprefix   = {arXiv}
}

@Online{fang24:_diffus_actor_critic,
  author          = {Linjiajie Fang AND Ruoxue Liu AND Jing Zhang AND Wenjia
                  Wang AND Bing-Yi Jing},
  title           = {{Diffusion Actor-Critic: Formulating Constrained Policy
                  Iteration as Diffusion Noise Regression for Offline
                  Reinforcement Learning}},
  year            = 2024,
  eprint          = {2405.20555v1},
  primaryclass    = {cs.LG},
  archiveprefix   = {arXiv}
}

@Online{psenka23:_learn_diffus_model_polic_rewar,
  author          = {Michael Psenka AND Alejandro Escontrela AND Pieter Abbeel
                  AND Yi Ma},
  title           = {{Learning a Diffusion Model Policy from Rewards via Q-Score
                  Matching}},
  year            = 2023,
  eprint          = {2312.11752v1},
  primaryclass    = {cs.LG},
  archiveprefix   = {arXiv}
}

@Article{DBLP:journals_corr_abs-2401-12244,
  author          = {Yinan Zhang and Eric Tzeng and Yilun Du and Dmitry Kislyuk},
  title           = {Large-scale Reinforcement Learning for Diffusion Models},
  journal         = {CoRR},
  year            = 2024,
  volume          = {abs/2401.12244},
  doi             = {10.48550/ARXIV.2401.12244},
  eprint          = {2401.12244},
  archiveprefix   = {arXiv}
}

@InProceedings{DBLP:conf/ijcai/BrownS17,
  author          = {Noam Brown and Tuomas Sandholm},
  title           = {Libratus: The Superhuman {AI} for No-Limit Poker},
  year            = 2017,
  booktitle       = {Proceedings of the Twenty-Sixth International Joint
                  Conference on Artificial Intelligence, {IJCAI} 2017,
                  Melbourne, Australia, August 19-25, 2017},
  pages           = {5226-5228},
  doi             = {10.24963/IJCAI.2017/772},
  url             = {https://doi.org/10.24963/ijcai.2017/772},
  crossref        = {DBLP:conf/ijcai/2017},
  timestamp       = {Tue, 20 Aug 2019 16:18:48 +0200},
  biburl          = {https://dblp.org/rec/conf/ijcai/BrownS17.bib},
  bibsource       = {dblp computer science bibliography, https://dblp.org}
}

@Online{bakhtin22:_master_game_no_press_diplom,
  author          = {Anton Bakhtin AND David J Wu AND Adam Lerer AND Jonathan
                  Gray AND Athul Paul Jacob AND Gabriele Farina AND Alexander H
                  Miller AND Noam Brown},
  title           = {{Mastering the Game of No-Press Diplomacy via
                  Human-Regularized Reinforcement Learning and Planning}},
  year            = 2022,
  eprint          = {2210.05492v1},
  primaryclass    = {cs.GT},
  archiveprefix   = {arXiv}
}

@Article{bakhtin22:_Human_level_diplomacy_cicero,
  author          = {Bakhtin, Anton and Brown, Noam and Dinan, Emily and Farina,
                  Gabriele and Flaherty, Colin and Fried, Daniel and Goff,
                  Andrew and Gray, Jonathan and Hu, Hengyuan and Jacob, Athul
                  Paul and Komeili, Mojtaba and Konath, Karthik and Kwon, Minae
                  and Lerer, Adam and Lewis, Mike and Miller, Alexander H. and
                  Mitts, Sasha and Renduchintala, Adithya and Roller, Stephen
                  and Rowe, Dirk and Shi, Weiyan and Spisak, Joe and Wei,
                  Alexander and Wu, David and Zhang, Hugh and Zijlstra, Markus},
  title           = {Human-level play in the game of Diplomacy by combining
                  language models with strategic reasoning},
  journal         = {Science},
  year            = 2022,
  volume          = 378,
  number          = 6624,
  month           = dec,
  pages           = {1067–1074},
  issn            = {1095-9203},
  doi             = {10.1126/science.ade9097},
  url             = {http://dx.doi.org/10.1126/science.ade9097},
  publisher       = {American Association for the Advancement of Science (AAAS)}
}

@Online{openai19:_dota_large_scale_deep_reinf_learn,
  author          = {OpenAI AND : AND Christopher Berner AND Greg Brockman AND
                  Brooke Chan AND Vicki Cheung AND Przemysław Dębiak AND Christy
                  Dennison AND David Farhi AND Quirin Fischer AND Shariq Hashme
                  AND Chris Hesse AND Rafal Józefowicz AND Scott Gray AND
                  Catherine Olsson AND Jakub Pachocki AND Michael Petrov AND
                  Henrique P. d. O. Pinto AND Jonathan Raiman AND Tim Salimans
                  AND Jeremy Schlatter AND Jonas Schneider AND Szymon Sidor AND
                  Ilya Sutskever AND Jie Tang AND Filip Wolski AND Susan Zhang},
  title           = {{Dota 2 with Large Scale Deep Reinforcement Learning}},
  year            = 2019,
  eprint          = {1912.06680v1},
  primaryclass    = {cs.LG},
  archiveprefix   = {arXiv}
}

@Online{mnih13:_playin_atari_deep_reinf_learn,
  author          = {Volodymyr Mnih AND Koray Kavukcuoglu AND David Silver AND
                  Alex Graves AND Ioannis Antonoglou AND Daan Wierstra AND
                  Martin Riedmiller},
  title           = {{Playing Atari with Deep Reinforcement Learning}},
  year            = 2013,
  eprint          = {1312.5602v1},
  primaryclass    = {cs.LG},
  archiveprefix   = {arXiv}
}

@Article{DBLP:journals/nature/SilverHMGSDSAPL16,
  author          = {David Silver and Aja Huang and Chris J. Maddison and Arthur
                  Guez and Laurent Sifre and George van den Driessche and Julian
                  Schrittwieser and Ioannis Antonoglou and Vedavyas
                  Panneershelvam and Marc Lanctot and Sander Dieleman and
                  Dominik Grewe and John Nham and Nal Kalchbrenner and Ilya
                  Sutskever and Timothy P. Lillicrap and Madeleine Leach and
                  Koray Kavukcuoglu and Thore Graepel and Demis Hassabis},
  title           = {Mastering the game of Go with deep neural networks and tree
                  search},
  journal         = {Nat.},
  year            = 2016,
  volume          = 529,
  number          = 7587,
  pages           = {484-489},
  doi             = {10.1038/NATURE16961},
  url             = {https://doi.org/10.1038/nature16961},
  timestamp       = {Mon, 27 Sep 2021 17:38:59 +0200},
  biburl          = {https://dblp.org/rec/journals/nature/SilverHMGSDSAPL16.bib},
  bibsource       = {dblp computer science bibliography, https://dblp.org}
}

@Online{kostrikov21:_offlin_reinf_learn_implic_q_learn,
  author          = {Ilya Kostrikov AND Ashvin Nair AND Sergey Levine},
  title           = {{Offline Reinforcement Learning with Implicit Q-Learning}},
  year            = 2021,
  eprint          = {2110.06169v1},
  primaryclass    = {cs.LG},
  archiveprefix   = {arXiv}
}

@Online{alonso24:_diffus_world_model,
  author          = {Eloi Alonso AND Adam Jelley AND Vincent Micheli AND Anssi
                  Kanervisto AND Amos Storkey AND Tim Pearce AND François
                  Fleuret},
  title           = {{Diffusion for World Modeling: Visual Details Matter in
                  Atari}},
  year            = 2024,
  eprint          = {2405.12399v1},
  primaryclass    = {cs.LG},
  archiveprefix   = {arXiv}
}

@Online{wang24:_diffus_actor_critic_entrop_regul,
  author          = {Yinuo Wang AND Likun Wang AND Yuxuan Jiang AND Wenjun Zou
                  AND Tong Liu AND Xujie Song AND Wenxuan Wang AND Liming Xiao
                  AND Jiang Wu AND Jingliang Duan AND Shengbo Eben Li},
  title           = {{Diffusion Actor-Critic with Entropy Regulator}},
  year            = 2024,
  eprint          = {2405.15177v2},
  primaryclass    = {cs.LG},
  archiveprefix   = {arXiv}
}

@Article{DBLP:journals/corr/abs-2402-04080,
  author          = {Ruoqi Zhang and Ziwei Luo and Jens Sj{\"{o}}lund and Thomas
                  B. Sch{\"{o}}n and Per Mattsson},
  title           = {Entropy-regularized Diffusion Policy with Q-Ensembles for
                  Offline Reinforcement Learning},
  journal         = {CoRR},
  year            = 2024,
  volume          = {abs/2402.04080},
  doi             = {10.48550/ARXIV.2402.04080},
  eprint          = {2402.04080},
  eprinttype      = {arXiv},
  url             = {https://doi.org/10.48550/arXiv.2402.04080},
  timestamp       = {Mon, 12 Feb 2024 17:35:51 +0100},
  biburl          = {https://dblp.org/rec/journals/corr/abs-2402-04080.bib},
  bibsource       = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{DBLP:conf/corl/SuhCDYGT23,
  author          = {H. J. Terry Suh and Glen Chou and Hongkai Dai and Lujie
                  Yang and Abhishek Gupta and Russ Tedrake},
  title           = {Fighting Uncertainty with Gradients: Offline Reinforcement
                  Learning via Diffusion Score Matching},
  year            = 2023,
  booktitle       = {Conference on Robot Learning, CoRL 2023, 6-9 November 2023,
                  Atlanta, GA, {USA}},
  pages           = {2878-2904},
  url             = {https://proceedings.mlr.press/v229/suh23a.html},
  crossref        = {DBLP:conf/corl/2023},
  timestamp       = {Tue, 20 Feb 2024 17:19:52 +0100},
  biburl          = {https://dblp.org/rec/conf/corl/SuhCDYGT23.bib},
  bibsource       = {dblp computer science bibliography, https://dblp.org}
}

@proceedings{DBLP:conf/corl/2023,
  editor          = {Jie Tan and Marc Toussaint and Kourosh Darvish},
  title           = {Conference on Robot Learning, CoRL 2023, 6-9 November 2023,
                  Atlanta, GA, {USA}},
  series          = {Proceedings of Machine Learning Research},
  volume          = 229,
  publisher       = {{PMLR}},
  year            = 2023,
  url             = {https://proceedings.mlr.press/v229/},
  timestamp       = {Mon, 17 Jun 2024 02:42:09 +0200},
  biburl          = {https://dblp.org/rec/conf/corl/2023.bib},
  bibsource       = {dblp computer science bibliography, https://dblp.org}
}

@Article{DBLP:journals/corr/abs-2305-13301,
  author          = {Kevin Black and Michael Janner and Yilun Du and Ilya
                  Kostrikov and Sergey Levine},
  title           = {Training Diffusion Models with Reinforcement Learning},
  journal         = {CoRR},
  year            = 2023,
  volume          = {abs/2305.13301},
  doi             = {10.48550/ARXIV.2305.13301},
  eprint          = {2305.13301},
  eprinttype      = {arXiv},
  url             = {https://doi.org/10.48550/arXiv.2305.13301},
  timestamp       = {Fri, 26 May 2023 11:29:33 +0200},
  biburl          = {https://dblp.org/rec/journals/corr/abs-2305-13301.bib},
  bibsource       = {dblp computer science bibliography, https://dblp.org}
}

@Article{DBLP:journals/corr/abs-2307-04726,
  author          = {Suzan Ece Ada and Erhan {\"{O}}ztop and Emre Ugur},
  title           = {Diffusion Policies for Out-of-Distribution Generalization
                  in Offline Reinforcement Learning},
  journal         = {CoRR},
  year            = 2023,
  volume          = {abs/2307.04726},
  doi             = {10.48550/ARXIV.2307.04726},
  eprint          = {2307.04726},
  eprinttype      = {arXiv},
  url             = {https://doi.org/10.48550/arXiv.2307.04726},
  timestamp       = {Mon, 05 Feb 2024 20:18:48 +0100},
  biburl          = {https://dblp.org/rec/journals/corr/abs-2307-04726.bib},
  bibsource       = {dblp computer science bibliography, https://dblp.org}
}

@Online{ho20:_denois_diffus_probab_model,
  author          = {Jonathan Ho AND Ajay Jain AND Pieter Abbeel},
  title           = {{Denoising Diffusion Probabilistic Models}},
  year            = 2020,
  eprint          = {2006.11239v2},
  primaryclass    = {cs.LG},
  archiveprefix   = {arXiv}
}

@Online{sun20:_canon_capsul,
  author          = {Weiwei Sun AND Andrea Tagliasacchi AND Boyang Deng AND Sara
                  Sabour AND Soroosh Yazdani AND Geoffrey Hinton AND Kwang Moo
                  Yi},
  title           = {{Canonical Capsules: Self-Supervised Capsules in Canonical
                  Pose}},
  year            = 2020,
  eprint          = {2012.04718v2},
  primaryclass    = {cs.CV},
  archiveprefix   = {arXiv}
}

@Online{hinton21:_how,
  author          = {Geoffrey Hinton},
  title           = {{How to represent part-whole hierarchies in a neural
                  network}},
  year            = 2021,
  eprint          = {2102.12627v1},
  primaryclass    = {cs.CV},
  archiveprefix   = {arXiv}
}

@misc{Irpan_2018,
  title           = {Deep Reinforcement Learning Doesn't Work Yet},
  author          = {Irpan, Alex},
  url             = {https://www.alexirpan.com/2018/02/14/rl-hard.html},
  year            = {2018-02-14}
}

@misc{Irpan_2024,
  title           = {My AI Timelines Have Sped Up (Again)},
  author          = {Irpan, Alex},
  url             =
                  {https://www.alexirpan.com/2024/01/10/ai-timelines-2024.html},
  year            = {2024-01-10}
}

@misc{TesslerChen_2021,
  title           = {Deep Reinforcement Learning Works - Now What?},
  author          = {Tessler, Chen},
  url             = {https://tesslerc.github.io/posts/drl_works_now_what/},
  year            = 2020
}

@misc{RietzFinn_2023,
  title           = {Multi-Objective Deep Reinforcement Learning with
                  Lexicographic Task-priority constraints},
  author          = {Rietz, Finn},
  url             =
                  {https://www.finnrietz.dev/machine%20learning/lexicographic-morl/},
  year            = 2023
}

@Article{DBLP:journals_ijrr_IbarzTFKPL21,
  author          = {Julian Ibarz and Jie Tan and Chelsea Finn and Mrinal
                  Kalakrishnan and Peter Pastor and Sergey Levine},
  title           = {How to train your robot with deep reinforcement learning:
                  lessons we have learned},
  journal         = {Int. J. Robotics Res.},
  year            = 2021,
  volume          = 40,
  number          = {4-5},
  doi             = {10.1177/0278364920987859},
  url             = {https://doi.org/10.1177/0278364920987859},
  timestamp       = {Sat, 09 Apr 2022 12:29:34 +0200},
  biburl          = {https://dblp.org/rec/journals/ijrr/IbarzTFKPL21.bib},
  bibsource       = {dblp computer science bibliography, https://dblp.org}
}

@Article{Delaware_2015,
  author          = {Delaware, Benjamin and Pit-Claudel, Clément and Gross,
                  Jason and Chlipala, Adam},
  title           = {Fiat: Deductive Synthesis of Abstract Data Types in a Proof
                  Assistant},
  journal         = {ACM SIGPLAN Notices},
  year            = 2015,
  volume          = 50,
  number          = 1,
  month           = jan,
  pages           = {689–700},
  issn            = {1558-1160},
  doi             = {10.1145/2775051.2677006},
  url             = {http://dx.doi.org/10.1145/2775051.2677006},
  publisher       = {Association for Computing Machinery (ACM)}
}

@Online{zheng18:_weigh_doubl_deep_multiag_reinf,
  author          = {Yan Zheng AND Jianye Hao AND Zongzhang Zhang},
  title           = {{Weighted Double Deep Multiagent Reinforcement Learning in
                  Stochastic Cooperative Environments}},
  year            = 2018,
  eprint          = {1802.08534v2},
  primaryclass    = {cs.MA},
  archiveprefix   = {arXiv}
}

@Online{fu22:_cooper_graph_approac_multiag_spars,
  author          = {Qingxu Fu AND Tenghai Qiu AND Zhiqiang Pu AND Jianqiang Yi
                  AND Wanmai Yuan},
  title           = {{A Cooperation Graph Approach for Multiagent Sparse Reward
                  Reinforcement Learning}},
  year            = 2022,
  eprint          = {2208.03002v1},
  primaryclass    = {cs.AI},
  archiveprefix   = {arXiv}
}

@Online{malialis19:_resour_abstr_reinf_learn_multiag_conges_probl,
  author          = {Kleanthis Malialis AND Sam Devlin AND Daniel Kudenko},
  title           = {{Resource Abstraction for Reinforcement Learning in
                  Multiagent Congestion Problems}},
  year            = 2019,
  eprint          = {1903.05431v1},
  primaryclass    = {cs.MA},
  archiveprefix   = {arXiv}
}

@Online{brockman16:_openai_gym,
  author          = {Greg Brockman AND Vicki Cheung AND Ludwig Pettersson AND
                  Jonas Schneider AND John Schulman AND Jie Tang AND Wojciech
                  Zaremba},
  title           = {{OpenAI Gym}},
  year            = 2016,
  eprint          = {1606.01540v1},
  primaryclass    = {cs.LG},
  archiveprefix   = {arXiv}
}

@Online{chen17:_ucb_explor_q_ensem,
  author          = {Richard Y. Chen AND Szymon Sidor AND Pieter Abbeel AND John
                  Schulman},
  title           = {{UCB Exploration via Q-Ensembles}},
  year            = 2017,
  eprint          = {1706.01502v3},
  primaryclass    = {cs.LG},
  archiveprefix   = {arXiv}
}

@Online{haarnoja18:_soft_actor_critic,
  author          = {Tuomas Haarnoja AND Aurick Zhou AND Pieter Abbeel AND
                  Sergey Levine},
  title           = {{Soft Actor-Critic: Off-Policy Maximum Entropy Deep
                  Reinforcement Learning with a Stochastic Actor}},
  year            = 2018,
  eprint          = {1801.01290v2},
  primaryclass    = {cs.LG},
  archiveprefix   = {arXiv}
}

@Online{orta22:_novel_lamb,
  author          = {Adil Han Orta AND Martin Roelfs AND Koen Van Den Abeele},
  title           = {{Novel algorithm for the computation of group and energy
                  velocities of Lamb waves}},
  year            = 2022,
  eprint          = {2205.11390v2},
  primaryclass    = {physics.app-ph},
  archiveprefix   = {arXiv}
}

@Article{DBLP:journals/corr/abs-1803-10122,
  author          = {David Ha and J{\"{u}}rgen Schmidhuber},
  title           = {World Models},
  journal         = {CoRR},
  year            = 2018,
  volume          = {abs/1803.10122},
  eprint          = {1803.10122},
  eprinttype      = {arXiv},
  url             = {http://arxiv.org/abs/1803.10122},
  timestamp       = {Mon, 13 Aug 2018 16:47:30 +0200},
  biburl          = {https://dblp.org/rec/journals/corr/abs-1803-10122.bib},
  bibsource       = {dblp computer science bibliography, https://dblp.org}
}

@Online{hafner18:_learn_laten_dynam_plann_pixel,
  author          = {Danijar Hafner AND Timothy Lillicrap AND Ian Fischer AND
                  Ruben Villegas AND David Ha AND Honglak Lee AND James
                  Davidson},
  title           = {{Learning Latent Dynamics for Planning from Pixels}},
  year            = 2018,
  eprint          = {1811.04551v5},
  primaryclass    = {cs.LG},
  archiveprefix   = {arXiv}
}

@Online{hafner20:_master_atari_discr_world_model,
  author          = {Danijar Hafner AND Timothy Lillicrap AND Mohammad Norouzi
                  AND Jimmy Ba},
  title           = {{Mastering Atari with Discrete World Models}},
  year            = 2020,
  eprint          = {2010.02193v4},
  primaryclass    = {cs.LG},
  archiveprefix   = {arXiv}
}

@Online{smith23:_grow_your_limit,
  author          = {Laura Smith AND Yunhao Cao AND Sergey Levine},
  title           = {{Grow Your Limits: Continuous Improvement with Real-World
                  RL for Robotic Locomotion}},
  year            = 2023,
  eprint          = {2310.17634v1},
  primaryclass    = {cs.RO},
  archiveprefix   = {arXiv}
}

@Online{kumar21:_rma,
  author          = {Ashish Kumar AND Zipeng Fu AND Deepak Pathak AND Jitendra
                  Malik},
  title           = {{RMA: Rapid Motor Adaptation for Legged Robots}},
  year            = 2021,
  eprint          = {2107.04034v1},
  primaryclass    = {cs.LG},
  archiveprefix   = {arXiv}
}

@Article{Miki_2022,
  author          = {Miki, Takahiro and Lee, Joonho and Hwangbo, Jemin and
                  Wellhausen, Lorenz and Koltun, Vladlen and Hutter, Marco},
  title           = {Learning robust perceptive locomotion for quadrupedal
                  robots in the wild},
  journal         = {Science Robotics},
  year            = 2022,
  volume          = 7,
  number          = 62,
  month           = jan,
  issn            = {2470-9476},
  doi             = {10.1126/scirobotics.abk2822},
  url             = {http://dx.doi.org/10.1126/scirobotics.abk2822},
  publisher       = {American Association for the Advancement of Science (AAAS)}
}

@Article{Song_2023,
  author          = {Song, Yunlong and Romero, Angel and Müller, Matthias and
                  Koltun, Vladlen and Scaramuzza, Davide},
  title           = {Reaching the limit in autonomous racing: Optimal control
                  versus reinforcement learning},
  journal         = {Science Robotics},
  year            = 2023,
  volume          = 8,
  number          = 82,
  month           = sep,
  issn            = {2470-9476},
  doi             = {10.1126/scirobotics.adg1462},
  url             = {http://dx.doi.org/10.1126/scirobotics.adg1462},
  publisher       = {American Association for the Advancement of Science (AAAS)}
}

@Article{Hoeller_2024,
  author          = {Hoeller, David and Rudin, Nikita and Sako, Dhionis and
                  Hutter, Marco},
  title           = {ANYmal parkour: Learning agile navigation for quadrupedal
                  robots},
  journal         = {Science Robotics},
  year            = 2024,
  volume          = 9,
  number          = 88,
  month           = mar,
  issn            = {2470-9476},
  doi             = {10.1126/scirobotics.adi7566},
  url             = {http://dx.doi.org/10.1126/scirobotics.adi7566},
  publisher       = {American Association for the Advancement of Science (AAAS)}
}

@Online{saunders17:_trial_error,
  author          = {William Saunders AND Girish Sastry AND Andreas Stuhlmueller
                  AND Owain Evans},
  title           = {{Trial without Error: Towards Safe Reinforcement Learning
                  via Human Intervention}},
  year            = 2017,
  eprint          = {1707.05173v1},
  primaryclass    = {cs.AI},
  archiveprefix   = {arXiv}
}

@Online{wu21:_human_loop_deep_reinf_learn,
  author          = {Jingda Wu AND Zhiyu Huang AND Chao Huang AND Zhongxu Hu AND
                  Peng Hang AND Yang Xing AND Chen Lv},
  title           = {{Human-in-the-Loop Deep Reinforcement Learning with
                  Application to Autonomous Driving}},
  year            = 2021,
  eprint          = {2104.07246v1},
  primaryclass    = {cs.RO},
  archiveprefix   = {arXiv}
}

@Online{goecks20:_human_loop_method_data_driven,
  author          = {Vinicius G. Goecks},
  title           = {{Human-in-the-Loop Methods for Data-Driven and
                  Reinforcement Learning Systems}},
  year            = 2020,
  eprint          = {2008.13221v1},
  primaryclass    = {cs.LG},
  archiveprefix   = {arXiv}
}

@Online{abel17:_agent_agnos_human_loop_reinf_learn,
  author          = {David Abel AND John Salvatier AND Andreas Stuhlmüller AND
                  Owain Evans},
  title           = {{Agent-Agnostic Human-in-the-Loop Reinforcement Learning}},
  year            = 2017,
  eprint          = {1701.04079v1},
  primaryclass    = {cs.LG},
  archiveprefix   = {arXiv}
}

@Article{Retzlaff_2024,
  author          = {Retzlaff, Carl Orge and Das, Srijita and Wayllace,
                  Christabel and Mousavi, Payam and Afshari, Mohammad and Yang,
                  Tianpei and Saranti, Anna and Angerschmid, Alessa and Taylor,
                  Matthew E. and Holzinger, Andreas},
  title           = {Human-in-the-Loop Reinforcement Learning: A Survey and
                  Position on Requirements, Challenges, and Opportunities},
  journal         = {Journal of Artificial Intelligence Research},
  year            = 2024,
  volume          = 79,
  month           = jan,
  pages           = {359–415},
  issn            = {1076-9757},
  doi             = {10.1613/jair.1.15348},
  url             = {http://dx.doi.org/10.1613/jair.1.15348},
  publisher       = {AI Access Foundation}
}

@Article{Huang_2023,
  author          = {Huang, Lin and Gong, Li},
  title           = {Agent behavior modeling method based on reinforcement
                  learning and human in the loop},
  journal         = {AIP Advances},
  year            = 2023,
  volume          = 13,
  number          = 6,
  month           = jun,
  issn            = {2158-3226},
  doi             = {10.1063/5.0152822},
  url             = {http://dx.doi.org/10.1063/5.0152822},
  publisher       = {AIP Publishing}
}
